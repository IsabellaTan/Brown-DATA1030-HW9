{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 9\n",
    "\n",
    "## Name: [TODO]\n",
    "\n",
    "## Link to your PS9 github repo: [TODO]\n",
    "\n",
    "### Problem 0 \n",
    "\n",
    "-2 points for every missing green OK sign. \n",
    "\n",
    "Make sure you are in the DATA1030 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.10\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.10\"):\n",
    "    print(FAIL, \"Python version 3.12.10 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"2.2.5\", 'matplotlib': \"3.10.1\",'sklearn': \"1.6.1\", \n",
    "                'pandas': \"2.2.3\",'xgboost': \"3.0.0\", 'shap': \"0.47.2\", \n",
    "                'polars': \"1.27.1\", 'seaborn': \"0.13.2\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction - ML Ethics \n",
    "\n",
    "In this problem set we'll explore algorithmic bias using a dataset containing information on criminal offenders screened in Florida from 2013 to 2014. The target variable (`two_year_recid`) for this dataset indicates whether or not an individual committed another crime after being released from prision. \n",
    "\n",
    "Machine learning models, known as Risk Assessment Tools (RATs), have been developed based on this and other similar datasets. The goal of these tools is to predict the likelihood of an individual commiting a future crime. These predictive scores are increasingly being used to inform decisions throughout the criminal justice system, including assigning bond amounts and determining sentencing lengths. As you can imagine, false positives and false negatives have severe consequences for the defendant and society in general.\n",
    "\n",
    "On top of this, the introduction of large language models (LLMs) has added new technical and moral considersations to the development of these predictive pipelines. Increasingly, LLMs are being integrated into the workflows of data scientists who are tasked with creating RATs and other socially centered tools. As such, we will also explore the benefits and limitations of using LLMs to develop socially critical machine learning pipelines.\n",
    "\n",
    "This problem set is broken down into the following sections:\n",
    "\n",
    "1. Use ChatGPT to perform EDA on the dataset and answer questions related to ChatGPT's effectiveness  \n",
    "2. Use ChatGPT to develop a machine learning pipeline, and discuss your findings\n",
    "3. Debug your inital pipeline and study the model's algorithmic bias\n",
    "\n",
    "**Throughout this problem set you should only be using the free version of ChatGPT.** If you have a ChatGPT subscription, please log out before you start solving this problem set. This will allow us to standardize the process across submissions. The csv file and a description are available in the `data` folder.\n",
    "\n",
    "You can read more about the topic [here](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) and [here](https://arxiv.org/pdf/2106.05498.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "In this section we'll perform EDA to get a better sense of our dataset and target variable. You should prompt ChatGPT to create graphics and feature descriptions that would be helpful for better understanding the data. Copy and paste the link to your ChatGPT conversation by clicking on the share icon in the top right hand corner on the ChatGPT UI. We list out several items that you should include in your EDA responses, but feel free to do as much EDA as you'd like! \n",
    "\n",
    "Note that you may need to drop some columns that clearly have no predictive power (i.e. id and name). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1a (5 points)\n",
    "\n",
    "Load in the dataset and perform EDA to show the following:\n",
    "\n",
    "1. The target variable (using .describe or .value_counts)\n",
    "3. The datatypes for each feature\n",
    "4. The fraction of missing values for each feature \n",
    "5. The unique races and genders in the dataset and how many people belong to each racial and gender group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666989455981,
     "user": {
      "displayName": "Tongtong Zhao",
      "userId": "04233586271954771797"
     },
     "user_tz": 240
    },
    "id": "_rKQ4oUlGmln"
   },
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1666989458811,
     "user": {
      "displayName": "Tongtong Zhao",
      "userId": "04233586271954771797"
     },
     "user_tz": 240
    },
    "id": "CXa5RZhwzUIr"
   },
   "source": [
    "### Problem 1b (10 points)\n",
    "\n",
    "Now let's have ChatGPT perform further EDA to develop the following plots. Keep in mind that we will use accuracy as the evaluation metric:\n",
    "\n",
    "1. Visualize the target variable \n",
    "    - Is the dataset balanced? \n",
    "    - What's the baseline accuracy? \n",
    "2. Prepare 3 figures to visualize correlations between various features and the target variable \n",
    "    - As usual, choose an appropriate visualization type, include axis labels and titles, and write a caption explaining what the figures show. \n",
    "    - One figure should show the target variable vs. gender and race.\n",
    "\n",
    "After completing the above EDA, answer the following questions:\n",
    "\n",
    "1. In your opinion, how good is ChatGPT at exploring datasets?\n",
    "2. Could ChatGPT correctly determine whether variables are continuous/ordinal/categorical?\n",
    "3. Could ChatGPT select appropriate figure types? Were the axes labeled and units shown?\n",
    "4. Did you encounter buggy code that you had to fix?\n",
    "\n",
    "Remember to share the link to your ChatGPT session!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "In this section, you will build an entire machine learning pipeline to predict the target variable using an XGBoost classifier. You will first use ChatGPT to generate the machine learning pipeline. Then, you'll examine ChatGPT's output and answer ethical questions regarding the use of LLMs for these types of tasks. Next, you'll debug the pipeline so that it can be used to generate predictions, which we can study for algorithmic bias. Remember you should only be using the free version of ChatGPT to answer these questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2a (6 points)\n",
    "\n",
    "Write a prompt that asks ChatGPT to generate a pipeline to perform the following:\n",
    "\n",
    "1. load in the data \n",
    "2. split the data (this dataset is IID)\n",
    "3. preprocesse the data \n",
    "4. train an XGBoost model \n",
    "    - tune at least one hyper parameter and use early stopping\n",
    "    - train on five different random states \n",
    "5. save train and test scores \n",
    "\n",
    "Copy in the prompt you used to generate the pipeline, as well as the code itself. You can also paste in the link to your ChatGPT conversation by clicking on the share icon in the top right hand corner. \n",
    "\n",
    "Answer the following questions:\n",
    "- What are the shortcomings of ChatGPT's work? Does the code run? If so, are the outputs as expected?\n",
    "- Besides buggy code, what is one technical issue with relying on ChatGPT to generate a pipeline?\n",
    "- What is one societal issue with relying on ChatGPT to generate a pipeline?\n",
    "- Given the issues you identified above, what role should LLMs play in the data science work stream?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your prompt here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ ChatGPT's ~ code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answers here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2b (10 points)\n",
    "\n",
    "Now let's debug ChatGPT's code to develop a working pipeline! You can either debug the code manually, or you can continue to prompt ChatGPT to fix previous mistakes. If you choose to further prompt ChatGPT, please include your full conversation by pasting in your session link as explained above. \n",
    "\n",
    "In addition to getting the pipeline up and running, please do the following:\n",
    "\n",
    "1. Save the test scores and 5 best models in lists \n",
    "2. Save each random state's test set into a list \n",
    "    - You should save both the feature matrix and the target series. We will use these sets later to evaluate our model for bias \n",
    "    - The sets should be converted into dataframes before being added to the list \n",
    "3. Plot the correlation coefficient matrix for the last random state using the training set \n",
    "    - Should any of the features be dropped? \n",
    "4. Print the mean and standard deviation of the test scores \n",
    "\n",
    "The pipeline we built for this assignment has an average test accuracy of 0.842 with a standard deviation of 0.012 across five random states. Your numbers may vary due to randomness but you should look for scores around these benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "In this final section, we will use the 5 best models to create predictions for each data point in the saved test sets. We will aggregate these predictions together into one dataframe that we can investigate for a more holistic overview of our models' performance. We will also study the bias that the model has for and against certain genders and races. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3a (10 points)\n",
    "\n",
    "In this problem, you will work with the 5 models and test sets that you saved in Problem 2. Specifically, use each of the models to predict the target labels of the data points in their corresponding test sets. You should concatenate these predictions, the true labels, and the original test sets into one master dataframe. For guidance, your final dataframe should have the shape: (`num_test_datapoints * 5, num_features + 2`). The two additional columns in this dataframe should be for the true and predicted values of each data point.\n",
    "\n",
    "Print out the overall accuracy of the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3b (6 points)\n",
    "\n",
    "We will now disaggregate the results and study the model's performance across various racial and gender groups. Let's focus on Caucasians and African-Americans because not many people belong to the other racial groups. \n",
    "\n",
    "Calculate and plot the following. The confusion matrices should be normalized with respect to the true conditions. We've provided the expected output for the female-only confusion matrix for your reference:\n",
    "\n",
    "1. overall accuracy and confusion matrix for males\n",
    "2. overall accuracy and confusion matrix for females\n",
    "3. overall accuracy and confusion matrix for Caucasians\n",
    "4. overall accuracy and confusion matrix for African-Americans\n",
    "\n",
    "Study the accuracies and the normalized false positives in the confusion matrices!\n",
    "\n",
    "Write a couple of paragraphs and discuss your findings. How do you feel about the overall accuracy of the model? Are there racial and gender groups for which the model performs better/worse? What do the false positives in the confusion matrix mean for criminal defendants?\n",
    "\n",
    "![alt text](images/confusion_mat.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
